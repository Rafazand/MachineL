{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rafazand/MachineL/blob/main/MachineL_Jobsheet4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lab Work 1**"
      ],
      "metadata": {
        "id": "Dnfpdj9_1S0m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 1 - Creating Dummy Data**"
      ],
      "metadata": {
        "id": "Xz4siBDH1u7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "# Create dummy data\n",
        "X,y = make_classification(n_samples=30, n_features=2, n_classes=2, n_informative=2, n_redundant=0, n_repeated=0, shuffle=False)\n",
        "\n",
        "# By default, make_classification function produce features in floating point\n",
        "# In this case, we want to make it as integer value\n",
        "\n",
        "# Convert to absolute point\n",
        "X = np.absolute(X)\n",
        "\n",
        "# Round to 2 decimal place\n",
        "X = np.round(X, 2) * 100\n",
        "\n",
        "# Convert to interger\n",
        "X = X.astype(int)\n",
        "print(X)\n",
        "print(y)"
      ],
      "metadata": {
        "id": "q_UPzoff2WPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (Optional) Creating DataFrame"
      ],
      "metadata": {
        "id": "_eD88f_Y2R9G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# We need to reshape the label 'y' to 2d array\n",
        "y_new = y.reshape(len(y), 1)\n",
        "\n",
        "# Concatenate features and labels\n",
        "data = np.concatenate((X, y_new), axis=1)\n",
        "\n",
        "# Create a list of columns name\n",
        "nama_kolom = ['Feature 1', 'Feature 2', 'Label']\n",
        "\n",
        "# Create Pandas DataFrame\n",
        "df = pd.DataFrame(data, columns=nama_kolom)\n",
        "\n",
        "# Check DataFrame\n",
        "df.head()"
      ],
      "metadata": {
        "id": "mXAXrAOI2lo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 2 - Convert Label to Categorical Value**"
      ],
      "metadata": {
        "id": "OESZMCmW2s3l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define categorical label\n",
        "labels = {\n",
        "    1 : 'Kelas A',\n",
        "    0 : 'Kelas B'\n",
        "}\n",
        "\n",
        "# Duplicate DataFrame\n",
        "df_label = df.copy()\n",
        "\n",
        "# Map new label to encoded label\n",
        "df_label['Label'] = df_label['Label'].map(labels)\n",
        "\n",
        "# Check\n",
        "df_label.head()"
      ],
      "metadata": {
        "id": "5w5_VPbW2vH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (Optional) Visualize The Data"
      ],
      "metadata": {
        "id": "qSPLk7o-27rE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the color for each class\n",
        "colors = {\n",
        "    'class_a': 'MediumVioletRed',\n",
        "    'class_b': 'Navy'\n",
        "}\n",
        "\n",
        "# Group by Label\n",
        "gb = df_label.groupby(['Label'])\n",
        "class_a = gb.get_group('Kelas A')\n",
        "class_b = gb.get_group('Kelas B')\n",
        "\n",
        "# Plot\n",
        "plt.scatter(x=class_a['Fitur 1'], y=class_a['Fitur 2'], c=colors['class_a'])\n",
        "plt.scatter(x=class_b['Fitur 1'], y=class_b['Fitur 2'], c=colors['class_b'])\n",
        "plt.xlabel('Fitur 1')\n",
        "plt.ylabel('Fitur 2')\n",
        "plt.legend(['Kelas A', 'Kelas B'])\n",
        "plt.gca().axes.xaxis.set_ticklabels([])\n",
        "plt.gca().axes.yaxis.set_ticklabels([])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WusLuJJW2_E9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 3 - Create Multinomial Naive Bayes Model**"
      ],
      "metadata": {
        "id": "70K_K78b2462"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Initiate the MultinomialNB object\n",
        "mnb = MultinomialNB()\n",
        "\n",
        "# We can use X and y from data dummy directly\n",
        "\n",
        "# Split data into training data and testing data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=30)\n",
        "\n",
        "# Fitting model\n",
        "# Label y should be in 1D arraylike form\n",
        "mnb.fit(X_train, y_train)\n",
        "\n",
        "# Make a prediction from train data\n",
        "y_train_pred = mnb.predict(X_train)\n",
        "\n",
        "# Make a prediction from test data\n",
        "y_test_pred = mnb.predict(X_test)"
      ],
      "metadata": {
        "id": "60nRxCNh3Wq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 4 - Model Evaluation**"
      ],
      "metadata": {
        "id": "_CVL-J2F3btp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# training accuracy\n",
        "acc_train = accuracy_score(y_train, y_train_pred)\n",
        "\n",
        "# testing accuracy\n",
        "acc_test = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "# Model evaluation on accuracy\n",
        "print(f'Hasil akurasi data train: {acc_train}')\n",
        "print(f'Hasil akurasi data test: {acc_test}')"
      ],
      "metadata": {
        "id": "hZ0ivYcK3dfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Gaussian Naive Bayes Model***"
      ],
      "metadata": {
        "id": "JHaJkhyW3pxm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Initiati GaussianNB object\n",
        "gnb = GaussianNB()\n",
        "\n",
        "# We will use the training and testing data from previous model\n",
        "\n",
        "# Fit model\n",
        "gnb.fit(X_train, y_train)\n",
        "\n",
        "# Make a prediction using training data\n",
        "y_train_pred_gnb = gnb.predict(X_train)\n",
        "\n",
        "# Evaluate training data accuracy\n",
        "acc_train_gnb = accuracy_score(y_train, y_train_pred_gnb)\n",
        "\n",
        "# Make a prediction using testing data\n",
        "y_test_pred_gnb = gnb.predict(X_test)\n",
        "\n",
        "# Evaluate testing data accuracy\n",
        "acc_test_gnb = accuracy_score(y_test, y_test_pred_gnb)\n",
        "\n",
        "# Print model evaluation\n",
        "print(f'Train Accuracy (Gaussian): {acc_train_gnb}')\n",
        "print(f'Test Accuracy (Gaussian): {acc_test_gnb}')"
      ],
      "metadata": {
        "id": "byyugmHJ3tP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lab Work 2**"
      ],
      "metadata": {
        "id": "N1lp0Bm-1au5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 1 - Load Data**"
      ],
      "metadata": {
        "id": "IhdZlmUz4DJv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Load data with specific encoding due data doesn't use utf-8 encoding\n",
        "df = pd.read_csv('spam.csv', encoding='latin-1')\n",
        "\n",
        "# Check\n",
        "df.head()"
      ],
      "metadata": {
        "id": "eCYfwX2H4IHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 2 - Preprocessing**"
      ],
      "metadata": {
        "id": "LRn55PA14UGL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2.1 - Drop Unecessary Columns"
      ],
      "metadata": {
        "id": "bIEHAnxw4aH4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop last 3 columns\n",
        "df = df.drop(df.iloc[:,2:], axis=1)\n",
        "\n",
        "# Check\n",
        "df.head()"
      ],
      "metadata": {
        "id": "aYYftQKr4nbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2.2 - Rename Columns Name\n"
      ],
      "metadata": {
        "id": "8IA2d9WV4qMq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename \"v1\" and \"v2\"\n",
        "new_cols = {\n",
        "    'v1': 'Labels',\n",
        "    'v2': 'SMS'\n",
        "}\n",
        "\n",
        "# Do renaming columns\n",
        "df = df.rename(columns=new_cols)\n",
        "\n",
        "# Check\n",
        "df.head()"
      ],
      "metadata": {
        "id": "Bpf2b48q4uBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2.3 - Data Inspection"
      ],
      "metadata": {
        "id": "eFUdhhkn4wNx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check data per class\n",
        "print(df['Labels'].value_counts())\n",
        "print('\\n')\n",
        "\n",
        "# Check general information\n",
        "print(df.info())\n",
        "print('\\n')\n",
        "\n",
        "# Check Descriptive Statistic Information\n",
        "print(df.describe())"
      ],
      "metadata": {
        "id": "GFCJB7lC4zvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2.4 - Label Encoding"
      ],
      "metadata": {
        "id": "FV5jsbQ_43X_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the labels\n",
        "new_labels = {\n",
        "    'spam': 1,\n",
        "    'ham': 0\n",
        "}\n",
        "\n",
        "# Encode\n",
        "df['Labels'] = df['Labels'].map(new_labels)\n",
        "\n",
        "# Check\n",
        "df.head()"
      ],
      "metadata": {
        "id": "8fPmk-Hv48MT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2.5 - Split Features and Labels"
      ],
      "metadata": {
        "id": "IZ20ZHoR5Aru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['SMS'].values\n",
        "y = df['Labels'].values"
      ],
      "metadata": {
        "id": "3zq2IFlA5DBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 3 - Features Extraction**\n",
        "\n"
      ],
      "metadata": {
        "id": "TLJGMcj05RbQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Split data training dan testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=50)\n",
        "\n",
        "# Initaite CountVectorizer\n",
        "bow = CountVectorizer()\n",
        "\n",
        "# Fitting and transform X_train using CountVectorizer\n",
        "X_train = bow.fit_transform(X_train)\n",
        "\n",
        "# Transform X_test\n",
        "# Why just transform? The reason is the same as in the third experiment.\n",
        "# We don't want the model to know the parameters used by CountVectorizer for fitting the X_train data.\n",
        "# Thus, the testing data can remain unfamiliar to the model.\n",
        "X_test = bow.transform(X_test)\n",
        "\n",
        "print(len(bow.get_feature_names()))\n",
        "print(f'Dimensi data: {X_train.shape}')"
      ],
      "metadata": {
        "id": "a5j-YLtv5cg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Training and Evaluation***"
      ],
      "metadata": {
        "id": "xcB7KuoB5kD-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Initiate MultinomialNB\n",
        "mnb = MultinomialNB()\n",
        "\n",
        "# Fit model\n",
        "mnb.fit(X_train, y_train)\n",
        "\n",
        "# Make a prediction using training data\n",
        "y_pred_train = mnb.predict(X_train)\n",
        "\n",
        "# Evaluate training data\n",
        "acc_train = accuracy_score(y_train, y_pred_train)\n",
        "\n",
        "# Make a prediction using testing data\n",
        "y_pred_test = mnb.predict(X_test)\n",
        "\n",
        "# Evaluate testing data\n",
        "acc_test = accuracy_score(y_test, y_pred_test)\n",
        "\n",
        "# Print model evaluation\n",
        "print(f'Training Accuracy: {acc_train}')\n",
        "print(f'Testing Accuracy: {acc_test}')"
      ],
      "metadata": {
        "id": "c_7h_5_H5p9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lab Work 3 (Linear SVM)**"
      ],
      "metadata": {
        "id": "uE01Pduo1ehd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 0 - Import Library**"
      ],
      "metadata": {
        "id": "hKulWoXr50IH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import library\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "SqrtKOaK5__K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 1 - Create Dummy Data**"
      ],
      "metadata": {
        "id": "yR50LXFP6JGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_blobs\n",
        "\n",
        "X, y = make_blobs(n_samples=50, centers=2,\n",
        "                  random_state=0, cluster_std=0.60)\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn')"
      ],
      "metadata": {
        "id": "Jfo9dfj66L2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 2 - Create Decision Boundaries**"
      ],
      "metadata": {
        "id": "SNe3qHrk6QCm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xfit = np.linspace(-1, 3.5)\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn')\n",
        "plt.plot([0.6], [2.1], 'x', color='red', markeredgewidth=2, markersize=10)\n",
        "\n",
        "for m, b in [(1, 0.65), (0.5, 1.6), (-0.2, 2.9)]:\n",
        "    plt.plot(xfit, m * xfit + b, '-k')\n",
        "\n",
        "plt.xlim(-1, 3.5)"
      ],
      "metadata": {
        "id": "1XakKcns6SQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 3 - Create Margins**\n"
      ],
      "metadata": {
        "id": "9eSozBp75GsF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xfit = np.linspace(-1, 3.5)\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn')\n",
        "\n",
        "for m, b, d in [(1, 0.65, 0.33), (0.5, 1.6, 0.55), (-0.2, 2.9, 0.2)]:\n",
        "    yfit = m * xfit + b\n",
        "    plt.plot(xfit, yfit, '-k')\n",
        "    plt.fill_between(xfit, yfit - d, yfit + d, edgecolor='none',\n",
        "                     color='#AAAAAA', alpha=0.4)\n",
        "\n",
        "plt.xlim(-1, 3.5)"
      ],
      "metadata": {
        "id": "Mn31UtKE5Mbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 4 - Model Fitting**"
      ],
      "metadata": {
        "id": "wGiZwCwu6kCs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC # \"Support vector classifier\"\n",
        "\n",
        "# Initaite SVC object\n",
        "model = SVC(kernel='linear', C=1E10)\n",
        "\n",
        "# Fitting\n",
        "model.fit(X, y)"
      ],
      "metadata": {
        "id": "Qr-RkR0l6nlj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4.1 - Visualize Fitting Model"
      ],
      "metadata": {
        "id": "ronAHtHz6qVr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a function to plot decision boundary\n",
        "\n",
        "def plot_svc_decision_function(model, ax=None, plot_support=True):\n",
        "\n",
        "    if ax is None:\n",
        "        ax = plt.gca()\n",
        "    xlim = ax.get_xlim()\n",
        "    ylim = ax.get_ylim()\n",
        "\n",
        "    # buat grid untuk evaluasi model\n",
        "    x = np.linspace(xlim[0], xlim[1], 30)\n",
        "    y = np.linspace(ylim[0], ylim[1], 30)\n",
        "    Y, X = np.meshgrid(y, x)\n",
        "    xy = np.vstack([X.ravel(), Y.ravel()]).T\n",
        "    P = model.decision_function(xy).reshape(X.shape)\n",
        "\n",
        "    # plot batas dan margin\n",
        "    ax.contour(X, Y, P, colors='k',\n",
        "               levels=[-1, 0, 1], alpha=0.5,\n",
        "               linestyles=['--', '-', '--'])\n",
        "\n",
        "    # plot support vectors\n",
        "    if plot_support:\n",
        "        ax.scatter(model.support_vectors_[:, 0],\n",
        "                   model.support_vectors_[:, 1],\n",
        "                   s=300, linewidth=1, facecolors='none');\n",
        "    ax.set_xlim(xlim)\n",
        "    ax.set_ylim(ylim)\n",
        "\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn')\n",
        "    plot_svc_decision_function(model)"
      ],
      "metadata": {
        "id": "_doF7zhB6uKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *Several data points that touch (enter) the area around the line are referred to as support vectors.*"
      ],
      "metadata": {
        "id": "Jspnn4Q46xi8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.support_vectors_\n",
        "\n",
        "def plot_svm(N=10, ax=None):\n",
        "    X, y = make_blobs(n_samples=200, centers=2,\n",
        "                      random_state=0, cluster_std=0.60)\n",
        "    X = X[:N]\n",
        "    y = y[:N]\n",
        "    model = SVC(kernel='linear', C=1E10)\n",
        "    model.fit(X, y)\n",
        "\n",
        "    ax = ax or plt.gca()\n",
        "    ax.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn')\n",
        "    ax.set_xlim(-1, 4)\n",
        "    ax.set_ylim(-1, 6)\n",
        "    plot_svc_decision_function(model, ax)\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n",
        "fig.subplots_adjust(left=0.0625, right=0.95, wspace=0.1)\n",
        "for axi, N in zip(ax, [60, 120]):\n",
        "    plot_svm(N, axi)\n",
        "    axi.set_title('N = {0}'.format(N))"
      ],
      "metadata": {
        "id": "tkorPMGO7GJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lab Work 3 (Non-Linear SVM)**"
      ],
      "metadata": {
        "id": "bpxbyB9F7Qbp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 1 - Create Dummy Data**"
      ],
      "metadata": {
        "id": "5Ec2fSj77Xbm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_circles\n",
        "X, y = make_circles(100, factor=.1, noise=.1)\n",
        "\n",
        "clf = SVC(kernel='linear').fit(X, y)\n",
        "\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn')\n",
        "plot_svc_decision_function(clf, plot_support=False);"
      ],
      "metadata": {
        "id": "YFW-coDA7eCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on the example data above, no linear separating line can be found that can serve as a data separator. Therefore, another perspective or projection of the data is needed to clearly separate the data. In this activity, the projection used is based on a radial basis. Since the radial projection doesn't suffice with a 2D model, the visualization plot is transformed into a 3D model."
      ],
      "metadata": {
        "id": "wZ2wRpuJ7cZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from mpl_toolkits import mplot3d\n",
        "\n",
        "def plot_3D(elev=30, azim=30, X=X, y=y):\n",
        "    ax = plt.subplot(projection='3d')\n",
        "    ax.scatter3D(X[:, 0], X[:, 1], r, c=y, s=50, cmap='autumn')\n",
        "    ax.view_init(elev=elev, azim=azim)\n",
        "    ax.set_xlabel('x')\n",
        "    ax.set_ylabel('y')\n",
        "    ax.set_zlabel('r')\n",
        "\n",
        "interact(plot_3D, elev=[-90, 45, 30, 20 , 10], azip=(-180, 180),\n",
        "         X=fixed(X), y=fixed(y))"
      ],
      "metadata": {
        "id": "4n7ZuRFI70DS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 2 - Fitting Model**"
      ],
      "metadata": {
        "id": "rrTkwNcO7-jT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = SVC(kernel='rbf', C=1E6)\n",
        "clf.fit(X, y)"
      ],
      "metadata": {
        "id": "pBuEERcK8GZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2.1 - Visualize Decision Boundary"
      ],
      "metadata": {
        "id": "xdrcq_hs8G_f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn')\n",
        "plot_svc_decision_function(clf)\n",
        "plt.scatter(clf.support_vectors_[:, 0], clf.support_vectors_[:, 1],\n",
        "            s=300, lw=1, facecolors='none')"
      ],
      "metadata": {
        "id": "xlvGPsJx8Kqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Case on Overlapping Data"
      ],
      "metadata": {
        "id": "R5YQF90-8UoV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = make_blobs(n_samples=100, centers=2,\n",
        "                  random_state=0, cluster_std=1.2)\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn');"
      ],
      "metadata": {
        "id": "8NYrtsmY8YU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### To address this, margin smoothing techniques in SVM can be applied. This technique involves incorporating some data points into the margin to achieve a better fit. The widening of the margin resulting from smoothing techniques is controlled by a tuning parameter (known as C). The example below demonstrates how changes in C can impact the final fitting result."
      ],
      "metadata": {
        "id": "6KtG4De88gts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = make_blobs(n_samples=100, centers=2,\n",
        "                  random_state=0, cluster_std=0.8)\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n",
        "fig.subplots_adjust(left=0.0625, right=0.95, wspace=0.1)\n",
        "\n",
        "for axi, C in zip(ax, [10.0, 0.1]):\n",
        "    model = SVC(kernel='linear', C=C).fit(X, y)\n",
        "    axi.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn')\n",
        "    plot_svc_decision_function(model, axi)\n",
        "    axi.scatter(model.support_vectors_[:, 0],\n",
        "                model.support_vectors_[:, 1],\n",
        "                s=300, lw=1, facecolors='none');\n",
        "    axi.set_title('C = {0:.1f}'.format(C), size=14)"
      ],
      "metadata": {
        "id": "ipj85_W38oE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lab Work 4**"
      ],
      "metadata": {
        "id": "IWh0ghtF1h_U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1 - Download The Dataset"
      ],
      "metadata": {
        "id": "thFPT3nw86_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_lfw_people\n",
        "\n",
        "# Store data in 'faces'\n",
        "faces = fetch_lfw_people(min_faces_per_person=60)\n",
        "\n",
        "# Check the dataset\n",
        "print(faces.target_names)\n",
        "print(len(faces.target_names))\n",
        "print(faces.images.shape)"
      ],
      "metadata": {
        "id": "rDhQ-yXT8_qa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2 - Visualize The Data"
      ],
      "metadata": {
        "id": "9ISMf3tX9CQF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We will plot some of the data\n",
        "\n",
        "fig, ax = plt.subplots(3, 5)\n",
        "for i, axi in enumerate(ax.flat):\n",
        "    axi.imshow(faces.images[i], cmap='bone')\n",
        "    axi.set(xticks=[], yticks=[],\n",
        "            xlabel=faces.target_names[faces.target[i]])"
      ],
      "metadata": {
        "id": "QESfj5ro9HwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3 - Dimensional Reduction and Model Initiation"
      ],
      "metadata": {
        "id": "QnKApzwg9Kej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.decomposition import PCA as RandomizedPCA\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# Notes that our image size is 62*47=2914\n",
        "# PCA reduce its dimension to 150\n",
        "pca = RandomizedPCA(n_components=150, whiten=True, random_state=42)\n",
        "\n",
        "# Intiate the SVM model\n",
        "svc = SVC(kernel='rbf', class_weight='balanced')\n",
        "\n",
        "# Create a pipeline -> Dimensional reduction followed by model fitting\n",
        "model = make_pipeline(pca, svc)"
      ],
      "metadata": {
        "id": "eMu4xJyE9UOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4 - Split Data"
      ],
      "metadata": {
        "id": "UZdM_S789XD6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(faces.data, faces.target,\n",
        "                                                random_state=42)"
      ],
      "metadata": {
        "id": "fKJf1KoE9Z6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5 - Perform Grid Search"
      ],
      "metadata": {
        "id": "7az8y14N9dpN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {'svc__C': [1, 5, 10, 50],\n",
        "              'svc__gamma': [0.0001, 0.0005, 0.001, 0.005]}\n",
        "grid = GridSearchCV(model, param_grid)\n",
        "\n",
        "%time grid.fit(Xtrain, ytrain)\n",
        "print(grid.best_params_)\n",
        "print(grid.best_score_)"
      ],
      "metadata": {
        "id": "WrOeCuF19f-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6 - Evaluate The Test Set"
      ],
      "metadata": {
        "id": "bxMsm3e39iM5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = grid.best_estimator_\n",
        "yfit = model.predict(Xtest)"
      ],
      "metadata": {
        "id": "CYdVFDSe9m9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 7 - Visualize The Prediction"
      ],
      "metadata": {
        "id": "tUN8QNS_9pdR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(4, 6)\n",
        "for i, axi in enumerate(ax.flat):\n",
        "    axi.imshow(Xtest[i].reshape(62, 47), cmap='bone')\n",
        "    axi.set(xticks=[], yticks=[])\n",
        "    axi.set_ylabel(faces.target_names[yfit[i]].split()[-1],\n",
        "                   color='black' if yfit[i] == ytest[i] else 'red')\n",
        "fig.suptitle('Predicted Names; Incorrect Labels in Red', size=14)"
      ],
      "metadata": {
        "id": "MESbf3kA9tHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 8 - Evaluate The Model"
      ],
      "metadata": {
        "id": "zt6EdE_l9sMf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(ytest, yfit,\n",
        "                            target_names=faces.target_names))"
      ],
      "metadata": {
        "id": "QzTXXG9t9ydc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check the confusion matrix,"
      ],
      "metadata": {
        "id": "TCZlj4uS94Bc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "mat = confusion_matrix(ytest, yfit)\n",
        "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
        "            xticklabels=faces.target_names,\n",
        "            yticklabels=faces.target_names)\n",
        "plt.xlabel('true label')\n",
        "plt.ylabel('predicted label')"
      ],
      "metadata": {
        "id": "1dLrQCz895zE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lab Assignment**"
      ],
      "metadata": {
        "id": "H1EWcaOd1ovm"
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}